package org.apache.spark.mllib.clustering

@org.apache.spark.annotation.Since("0.8.0")
class KMeansModel(@org.apache.spark.annotation.Since("1.0.0") val clusterCenters: scala.Array[org.apache.spark.mllib.linalg.Vector]) extends scala.AnyRef with org.apache.spark.mllib.util.Saveable with scala.Serializable with org.apache.spark.mllib.pmml.PMMLExportable {
  @org.apache.spark.annotation.Since("1.4.0")
  def this(centers: java.lang.Iterable[org.apache.spark.mllib.linalg.Vector]) = ???

  @org.apache.spark.annotation.Since("0.8.0")
  def k: scala.Int = ???

  @org.apache.spark.annotation.Since("0.8.0")
  def predict(point: org.apache.spark.mllib.linalg.Vector): scala.Int = ???

  @org.apache.spark.annotation.Since("1.0.0")
  def predict(points: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector]): org.apache.spark.rdd.RDD[scala.Int] = ???

  @org.apache.spark.annotation.Since("1.0.0")
  def predict(points: org.apache.spark.api.java.JavaRDD[org.apache.spark.mllib.linalg.Vector]): org.apache.spark.api.java.JavaRDD[java.lang.Integer] = ???

  @org.apache.spark.annotation.Since("0.8.0")
  def computeCost(data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector]): scala.Double = ???

  @org.apache.spark.annotation.Since("1.4.0")
  override def save(sc: org.apache.spark.SparkContext, path: scala.Predef.String): scala.Unit = ???

  protected override def formatVersion: scala.Predef.String = ???
}

@org.apache.spark.annotation.Since("1.4.0")
object KMeansModel extends scala.AnyRef with org.apache.spark.mllib.util.Loader[org.apache.spark.mllib.clustering.KMeansModel] with scala.Serializable {
  @org.apache.spark.annotation.Since("1.4.0")
  override def load(sc: org.apache.spark.SparkContext, path: scala.Predef.String): org.apache.spark.mllib.clustering.KMeansModel = ???

  private object Cluster extends scala.AnyRef with scala.Serializable {
    def apply(r: org.apache.spark.sql.Row): org.apache.spark.mllib.clustering.KMeansModel.Cluster = ???
  }

  private[clustering] object SaveLoadV1_0 extends scala.AnyRef {
    private[clustering] val thisClassName: java.lang.String = ???

    def save(sc: org.apache.spark.SparkContext, model: org.apache.spark.mllib.clustering.KMeansModel, path: scala.Predef.String): scala.Unit = ???

    def load(sc: org.apache.spark.SparkContext, path: scala.Predef.String): org.apache.spark.mllib.clustering.KMeansModel = ???
  }
}
